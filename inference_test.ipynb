{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "data_dir = '/Users/lukgar/Desktop/exjobb/datasets/LJSpeech-1.1/wavs'\n",
    "model_dir = 'diffwave-ljspeech-22kHz-1000578.pt'\n",
    "\n",
    "filename = data_dir + '/LJ001-0004.wav'\n",
    "from diffwave.preprocess import transform\n",
    "\n",
    "spec = transform(filename, save=False)\n",
    "spectrogram = spec.view(1, *spec.shape)\n",
    "\n",
    "print(spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "def play_audio(waveform, sample_rate):\n",
    "  waveform = waveform.cpu().numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  if num_channels == 1:\n",
    "    display(Audio(waveform[0], rate=sample_rate))\n",
    "  elif num_channels == 2:\n",
    "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
    "  else:\n",
    "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n",
    "\n",
    "from diffwave.inference import predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr = predict(spectrogram, model_dir, device=torch.device('cpu'), fast_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 second clip on cpu took 90 seconds -> ratio = 10\n",
    "\n",
    "5 second clip on gpu took 9 seconds -> ratio = 1.8\n",
    "\n",
    "ideally we want an inference ratio of 0.2? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 second clip, 90 second inference time on\n",
    "# cpu, gives a ratio of 10\n",
    "\n",
    "9/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "filenames = glob('wavs/**/*.wav', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('diffwave')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2194d696917787ee295fa48219bd356ec9ef563b926c2c309643f8314e0c2bc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
